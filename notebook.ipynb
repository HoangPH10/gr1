{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom tensorflow.keras.layers.experimental.preprocessing import StringLookup\nfrom tensorflow import keras\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import Conv2D, Bidirectional, LSTM, GRU, Dense\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, PReLU, Layer\nfrom tensorflow.keras.layers import Input, Add, Activation, Lambda, MaxPooling2D, Reshape\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow import keras\nnp.random.seed(42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-14T01:44:40.792217Z","iopub.execute_input":"2022-06-14T01:44:40.792581Z","iopub.status.idle":"2022-06-14T01:44:46.078112Z","shell.execute_reply.started":"2022-06-14T01:44:40.792486Z","shell.execute_reply":"2022-06-14T01:44:46.077316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = \"../input/iam-words/IAM_Words\"\nwords_list = []\n\nwords = open(f\"{base_path}/words.txt\", \"r\").readlines()\nfor line in words:\n    if line[0] == \"#\":\n        continue\n    if line.split(\" \")[1] != \"err\":  # We don't need to deal with errored entries.\n        words_list.append(line)\n\nprint(len(words_list))\n\nnp.random.shuffle(words_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:44:46.079775Z","iopub.execute_input":"2022-06-14T01:44:46.080015Z","iopub.status.idle":"2022-06-14T01:44:46.31674Z","shell.execute_reply.started":"2022-06-14T01:44:46.079982Z","shell.execute_reply":"2022-06-14T01:44:46.315963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_idx = int(0.9 * len(words_list))\ntrain_samples = words_list[:split_idx]\ntest_samples = words_list[split_idx:]\n\nval_split_idx = int(0.5 * len(test_samples))\nvalidation_samples = test_samples[:val_split_idx]\ntest_samples = test_samples[val_split_idx:]\n\nassert len(words_list) == len(train_samples) + len(validation_samples) + len(\n    test_samples\n)\n\nprint(f\"Total training samples: {len(train_samples)}\")\nprint(f\"Total validation samples: {len(validation_samples)}\")\nprint(f\"Total test samples: {len(test_samples)}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:44:46.318239Z","iopub.execute_input":"2022-06-14T01:44:46.318721Z","iopub.status.idle":"2022-06-14T01:44:46.331021Z","shell.execute_reply.started":"2022-06-14T01:44:46.318682Z","shell.execute_reply":"2022-06-14T01:44:46.330192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_image_path = os.path.join(base_path, \"words\")\n\n\ndef get_image_paths_and_labels(samples):\n    paths = []\n    corrected_samples = []\n    for (i, file_line) in enumerate(samples):\n        line_split = file_line.strip()\n        line_split = line_split.split(\" \")\n\n        # Each line split will have this format for the corresponding image:\n        # part1/part1-part2/part1-part2-part3.png\n        image_name = line_split[0]\n        partI = image_name.split(\"-\")[0]\n        partII = image_name.split(\"-\")[1]\n        img_path = os.path.join(\n            base_image_path, partI, partI + \"-\" + partII, image_name + \".png\"\n        )\n        if os.path.getsize(img_path):\n            paths.append(img_path)\n            corrected_samples.append(file_line.split(\"\\n\")[0])\n\n    return paths, corrected_samples\n\n\ntrain_img_paths, train_labels = get_image_paths_and_labels(train_samples)\nvalidation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples)\ntest_img_paths, test_labels = get_image_paths_and_labels(test_samples)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:44:46.333398Z","iopub.execute_input":"2022-06-14T01:44:46.33371Z","iopub.status.idle":"2022-06-14T01:49:20.164611Z","shell.execute_reply.started":"2022-06-14T01:44:46.333672Z","shell.execute_reply":"2022-06-14T01:49:20.163848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:20.167334Z","iopub.execute_input":"2022-06-14T01:49:20.16801Z","iopub.status.idle":"2022-06-14T01:49:20.175595Z","shell.execute_reply.started":"2022-06-14T01:49:20.167981Z","shell.execute_reply":"2022-06-14T01:49:20.174663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find maximum length and the size of the vocabulary in the training data.\ntrain_labels_cleaned = []\n#characters = set()\nmax_len = 0\n\nfor label in train_labels:\n    label = label.split(\" \")[-1].strip()\n    max_len = max(max_len, len(label))\n    train_labels_cleaned.append(label)\n\n# print(\"Maximum length: \", max_len)\n# print(\"Vocab size: \", len(characters))\n\n# Check some label samples.\n# with open('./token.txt','w+') as token:\n#     for char in characters:\n#         token.writelines(char + '\\n')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:20.1771Z","iopub.execute_input":"2022-06-14T01:49:20.177591Z","iopub.status.idle":"2022-06-14T01:49:20.28165Z","shell.execute_reply.started":"2022-06-14T01:49:20.177555Z","shell.execute_reply":"2022-06-14T01:49:20.280979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"characters = []\nwith open('../input/char-token/char_token.txt','r') as token:\n    for char in token.readlines()[0]:\n        characters.append(char)\nlen(characters)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:20.282698Z","iopub.execute_input":"2022-06-14T01:49:20.282946Z","iopub.status.idle":"2022-06-14T01:49:20.305829Z","shell.execute_reply.started":"2022-06-14T01:49:20.28291Z","shell.execute_reply":"2022-06-14T01:49:20.305132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_labels(labels):\n    cleaned_labels = []\n    for label in labels:\n        label = label.split(\" \")[-1].strip()\n        cleaned_labels.append(label)\n    return cleaned_labels\n\n\nvalidation_labels_cleaned = clean_labels(validation_labels)\ntest_labels_cleaned = clean_labels(test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:20.307031Z","iopub.execute_input":"2022-06-14T01:49:20.307293Z","iopub.status.idle":"2022-06-14T01:49:20.322123Z","shell.execute_reply.started":"2022-06-14T01:49:20.307255Z","shell.execute_reply":"2022-06-14T01:49:20.321267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n# Mapping characters to integers.\nchar_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\nprint(char_to_num.get_vocabulary())\n# Mapping integers back to original characters.\nnum_to_char = StringLookup(\n    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:20.323766Z","iopub.execute_input":"2022-06-14T01:49:20.324076Z","iopub.status.idle":"2022-06-14T01:49:22.976776Z","shell.execute_reply.started":"2022-06-14T01:49:20.32404Z","shell.execute_reply":"2022-06-14T01:49:22.975882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def distortion_free_resize(image, img_size):\n    w, h = img_size\n    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n\n    # Check tha amount of padding needed to be done.\n    pad_height = h - tf.shape(image)[0]\n    pad_width = w - tf.shape(image)[1]\n\n    # Only necessary if you want to do same amount of padding on both sides.\n    if pad_height % 2 != 0:\n        height = pad_height // 2\n        pad_height_top = height + 1\n        pad_height_bottom = height\n    else:\n        pad_height_top = pad_height_bottom = pad_height // 2\n\n    if pad_width % 2 != 0:\n        width = pad_width // 2\n        pad_width_left = width + 1\n        pad_width_right = width\n    else:\n        pad_width_left = pad_width_right = pad_width // 2\n\n    image = tf.pad(\n        image,\n        paddings=[\n            [pad_height_top, pad_height_bottom],\n            [pad_width_left, pad_width_right],\n            [0, 0],\n        ],\n    )\n\n    image = tf.transpose(image, perm=[1, 0, 2])\n    image = tf.image.flip_left_right(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:22.979941Z","iopub.execute_input":"2022-06-14T01:49:22.980345Z","iopub.status.idle":"2022-06-14T01:49:22.989841Z","shell.execute_reply.started":"2022-06-14T01:49:22.980306Z","shell.execute_reply":"2022-06-14T01:49:22.988808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\npadding_token = 99\nimage_width = 256\nimage_height = 64\ndef preprocess_image(image_path, img_size=(image_width, image_height)):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, 1)\n    image = distortion_free_resize(image, img_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\ndef vectorize_label(label):\n    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n    length = tf.shape(label)[0]\n    pad_amount = max_len - length\n    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n    return label\n\ndef process_images_labels(image_path, label):\n    image = preprocess_image(image_path)\n    label = vectorize_label(label)\n    return {\"input\": image, \"label\": label}\n\n\ndef prepare_dataset(image_paths, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n        process_images_labels, num_parallel_calls=AUTOTUNE\n    )\n    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:22.991154Z","iopub.execute_input":"2022-06-14T01:49:22.991525Z","iopub.status.idle":"2022-06-14T01:49:23.004227Z","shell.execute_reply.started":"2022-06-14T01:49:22.991485Z","shell.execute_reply":"2022-06-14T01:49:23.003408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = prepare_dataset(train_img_paths, train_labels_cleaned)\nvalidation_ds = prepare_dataset(validation_img_paths, validation_labels_cleaned)\ntest_ds = prepare_dataset(test_img_paths, test_labels_cleaned)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:23.005521Z","iopub.execute_input":"2022-06-14T01:49:23.006381Z","iopub.status.idle":"2022-06-14T01:49:24.537632Z","shell.execute_reply.started":"2022-06-14T01:49:23.006331Z","shell.execute_reply":"2022-06-14T01:49:24.536853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:24.538988Z","iopub.execute_input":"2022-06-14T01:49:24.541114Z","iopub.status.idle":"2022-06-14T01:49:24.547918Z","shell.execute_reply.started":"2022-06-14T01:49:24.541073Z","shell.execute_reply":"2022-06-14T01:49:24.546984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CTCLayer(Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        # At test time, just return the computed predictions.\n        return y_pred\n\n\ndef build_model():\n    # Inputs to the model\n    input_data = Input(name=\"input\", shape=(image_width, image_height, 1))\n    labels = Input(name=\"label\", shape=(None,))\n\n    # First conv block.\n    cnn = Conv2D(filters=16, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\n    cnn = PReLU(shared_axes=[1, 2])(cnn)\n    cnn = BatchNormalization(renorm=True)(cnn)\n    cnn = Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\")(cnn)\n\n    # Second conv block.\n    cnn = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_uniform\")(cnn)\n    cnn = PReLU(shared_axes=[1, 2])(cnn)\n    cnn = BatchNormalization(renorm=True)(cnn)\n    cnn = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\")(cnn)\n\n    cnn = Conv2D(filters=40, kernel_size=(2, 4), strides=(2, 4), padding=\"same\", kernel_initializer=\"he_uniform\")(cnn)\n    cnn = PReLU(shared_axes=[1, 2])(cnn)\n    cnn = BatchNormalization(renorm=True)(cnn)\n    cnn = Conv2D(filters=40, kernel_size=(3, 3), padding=\"same\", kernel_constraint=MaxNorm(4, [0, 1, 2]))(cnn)\n    cnn = Dropout(rate=0.2)(cnn)\n\n    cnn = Conv2D(filters=48, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_uniform\")(cnn)\n    cnn = PReLU(shared_axes=[1, 2])(cnn)\n    cnn = BatchNormalization(renorm=True)(cnn)\n    cnn = Conv2D(filters=48, kernel_size=(3, 3), padding=\"same\", kernel_constraint=MaxNorm(4, [0, 1, 2]))(cnn)\n    cnn = Dropout(rate=0.2)(cnn)\n\n    cnn = Conv2D(filters=56, kernel_size=(2, 4), strides=(2, 4), padding=\"same\", kernel_initializer=\"he_uniform\")(cnn)\n    cnn = PReLU(shared_axes=[1, 2])(cnn)\n    cnn = BatchNormalization(renorm=True)(cnn)\n    cnn = Conv2D(filters=56, kernel_size=(3, 3), padding=\"same\", kernel_constraint=MaxNorm(4, [0, 1, 2]))(cnn)\n    cnn = Dropout(rate=0.2)(cnn)\n\n    cnn = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=\"he_uniform\")(cnn)\n    cnn = PReLU(shared_axes=[1, 2])(cnn)\n    cnn = BatchNormalization(renorm=True)(cnn)\n    \n    cnn = MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding=\"valid\")(cnn)\n\n    print(cnn.get_shape())\n\n    shape = cnn.get_shape()\n\n    bgru = Reshape(( shape[1] , shape[2] * shape[3]))(cnn)\n\n    bgru = Bidirectional(GRU(units=128, return_sequences=True, dropout=0.5))(bgru)\n    bgru = Dense(units=256)(bgru)\n\n    bgru = Bidirectional(GRU(units=128, return_sequences=True, dropout=0.5))(bgru)\n    \n\n    output_data = Dense(\n        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense2\"\n    )(bgru)\n\n    # Add CTC layer for calculating CTC loss at each step.\n    output = CTCLayer(name=\"ctc_loss\")(labels, output_data)\n\n    # Define the model.\n    model = keras.models.Model(\n        inputs=[input_data, labels], outputs=output, name=\"handwriting_recognizer\"\n    )\n    # Optimizer.\n    opt = keras.optimizers.Adam()\n    # Compile the model and return.\n    model.compile(optimizer=opt)\n    return model\n\n\n# Get the model.\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:24.54921Z","iopub.execute_input":"2022-06-14T01:49:24.54959Z","iopub.status.idle":"2022-06-14T01:49:25.806093Z","shell.execute_reply.started":"2022-06-14T01:49:24.549551Z","shell.execute_reply":"2022-06-14T01:49:25.805091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_images = []\nvalidation_labels = []\n\nfor batch in validation_ds:\n    validation_images.append(batch[\"input\"])\n    validation_labels.append(batch[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:25.807361Z","iopub.execute_input":"2022-06-14T01:49:25.807636Z","iopub.status.idle":"2022-06-14T01:49:43.476096Z","shell.execute_reply.started":"2022-06-14T01:49:25.807596Z","shell.execute_reply":"2022-06-14T01:49:43.47537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\n\nmodel = build_model()\nprediction_model = keras.models.Model(\n    model.get_layer(name=\"input\").input, model.get_layer(name=\"dense2\").output\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:43.477817Z","iopub.execute_input":"2022-06-14T01:49:43.478248Z","iopub.status.idle":"2022-06-14T01:49:44.831036Z","shell.execute_reply.started":"2022-06-14T01:49:43.478208Z","shell.execute_reply":"2022-06-14T01:49:44.830283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model.\nhistory = model.fit(\n    train_ds,\n    validation_data=validation_ds,\n    epochs=epochs,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T01:49:44.832582Z","iopub.execute_input":"2022-06-14T01:49:44.832837Z","iopub.status.idle":"2022-06-14T05:13:49.514367Z","shell.execute_reply.started":"2022-06-14T01:49:44.832802Z","shell.execute_reply":"2022-06-14T05:13:49.513559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open('./weightsBethham_model.json', 'w') as json_file:\n    json_file.write(model_json)\n\nfrom keras.models import save_model\nnetwork1_saved = save_model(model, './weightsBethham_model.hdf5')\n\n\nmodel_json = prediction_model.to_json()\nwith open('./weightsBethham_prediction_model.json', 'w') as json_file:\n    json_file.write(model_json)\n\nfrom keras.models import save_model\nnetwork2_saved = save_model(model, './weightsBethham_prediction_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:13:49.518505Z","iopub.execute_input":"2022-06-14T05:13:49.51874Z","iopub.status.idle":"2022-06-14T05:13:49.935933Z","shell.execute_reply.started":"2022-06-14T05:13:49.518711Z","shell.execute_reply":"2022-06-14T05:13:49.9351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/aimweights2/weightsBethham_prediction_model.json','r') as json_file:\n    json_saved_model = json_file.read()\njson_saved_model\nprediction_model_saved = tf.keras.models.model_from_json(json_saved_model)\nprediction_model_saved.load_weights('../input/aimweights2/weightsBethham_prediction_model.hdf5')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:13:49.937328Z","iopub.execute_input":"2022-06-14T05:13:49.937632Z","iopub.status.idle":"2022-06-14T05:13:51.088844Z","shell.execute_reply.started":"2022-06-14T05:13:49.937592Z","shell.execute_reply":"2022-06-14T05:13:51.08795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A utility function to decode the output of the network.\ndef decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search. For complex tasks, you can use beam search.\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results and get back the text.\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:13:51.090153Z","iopub.execute_input":"2022-06-14T05:13:51.090447Z","iopub.status.idle":"2022-06-14T05:13:51.098236Z","shell.execute_reply.started":"2022-06-14T05:13:51.090388Z","shell.execute_reply":"2022-06-14T05:13:51.097227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:13:51.099765Z","iopub.execute_input":"2022-06-14T05:13:51.100273Z","iopub.status.idle":"2022-06-14T05:13:51.110318Z","shell.execute_reply.started":"2022-06-14T05:13:51.100229Z","shell.execute_reply":"2022-06-14T05:13:51.109263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_batch_origin(batch):\n    out_put = []\n    for res in batch['label']:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, 99)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        out_put.append(res)\n    return out_put\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:13:51.111971Z","iopub.execute_input":"2022-06-14T05:13:51.112317Z","iopub.status.idle":"2022-06-14T05:13:51.119337Z","shell.execute_reply.started":"2022-06-14T05:13:51.112274Z","shell.execute_reply":"2022-06-14T05:13:51.118474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A utility function to decode the output of the network.\ndef decode_batch_predictions(pred):\n    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n    # Use greedy search. For complex tasks, you can use beam search.\n    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n        :, :max_len\n    ]\n    # Iterate over the results and get back the text.\n    output_text = []\n    for res in results:\n        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n        output_text.append(res)\n    return output_text\n\n\n#  Let's check results on some test samples.\n\nfor batch in test_ds.take(10):\n    batch_images = batch[\"input\"]\n    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n    preds = prediction_model_saved.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    original_texts = decode_batch_origin(batch)\n\n    for i in range(16):\n        img = batch_images[i]\n        img = tf.image.flip_left_right(img)\n        img = tf.transpose(img, perm=[1, 0, 2])\n        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n        img = img[:, :, 0]\n\n        title = f\"Prediction: {pred_texts[i]} \\n Origin: {original_texts[i]}\"\n        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n        ax[i // 4, i % 4].set_title(title)\n        ax[i // 4, i % 4].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:13:51.121292Z","iopub.execute_input":"2022-06-14T05:13:51.121645Z","iopub.status.idle":"2022-06-14T05:14:05.618731Z","shell.execute_reply.started":"2022-06-14T05:13:51.121606Z","shell.execute_reply":"2022-06-14T05:14:05.617911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Let's check results on some test samples.\nword_count = 0\nword_total = 0\ncharacter_count = 0\ncharacter_total = 0\nfor batch in test_ds:\n    batch_images = batch[\"input\"]\n    preds = prediction_model_saved.predict(batch_images)\n    pred_texts = decode_batch_predictions(preds)\n    original_texts = decode_batch_origin(batch)\n    \n    for i in range (16):\n        if pred_texts[i] == original_texts[i]:\n            word_count += 1\n        word_total += 1\n        for k in range(0,len(original_texts[i])):\n            try:\n                if original_texts[i][k] == pred_texts[i][k]:\n                    character_count += 1\n                character_total += 1\n            except:\n                continue\n#         print('Original:' , test_labels_cleaned[i])\n#         print('Predicted:' , pred_texts[i])\nprint('Character_count: ', character_count )\nprint('Character_total: ', character_total )\nprint('Character Accuracy: ', character_count/character_total*100 )\n\nprint('Word_count: ', word_count )\nprint('Word_total: ', word_total )\nprint('Word Accuracy: ', word_count/word_total*100 )\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:14:05.619935Z","iopub.execute_input":"2022-06-14T05:14:05.620858Z","iopub.status.idle":"2022-06-14T05:14:46.651235Z","shell.execute_reply.started":"2022-06-14T05:14:05.620813Z","shell.execute_reply":"2022-06-14T05:14:46.650445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image = preprocess_image('../input/test-data/image.png')\n# image = tf.expand_dims(image, axis=0)\n\n\n\n\n\n# _, ax = plt.subplots(4, 4, figsize=(15, 8))\n\n# preds = prediction_model_saved.predict(image)\n# pred_texts = decode_batch_predictions(preds)\n\n# for i in range(1):\n#     img = image[i]\n#     img = tf.image.flip_left_right(img)\n#     img = tf.transpose(img, perm=[1, 0, 2])\n#     img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n#     img = img[:, :, 0]\n\n#     title = f\"Prediction: {pred_texts[i]} \\n Origin: {original_texts[i]}\"\n#     ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n#     ax[i // 4, i % 4].set_title(title)\n#     ax[i // 4, i % 4].axis(\"off\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:14:46.652734Z","iopub.execute_input":"2022-06-14T05:14:46.653104Z","iopub.status.idle":"2022-06-14T05:14:46.658454Z","shell.execute_reply.started":"2022-06-14T05:14:46.653061Z","shell.execute_reply":"2022-06-14T05:14:46.657655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}